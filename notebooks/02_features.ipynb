{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e5ba2a6",
   "metadata": {},
   "source": [
    "# Step 2 – Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ad52a7",
   "metadata": {},
   "source": [
    "Basic imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "867227cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test  = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c419af4",
   "metadata": {},
   "source": [
    "Handle literal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82fc2490",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['ethnicity', 'relation']:\n",
    "    for df in (train, test):\n",
    "        df[col] = df[col].astype(str).replace('?', np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd04695",
   "metadata": {},
   "source": [
    "Build feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1e3df1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Columns to use\n",
    "num_cols   = ['age', 'result']          # we’ll test with/without 'result'\n",
    "cat_cols   = ['gender','ethnicity','jaundice','austim','contry_of_res','used_app_before','relation']\n",
    "a_cols     = [f'A{i}_Score' for i in range(1,11)]\n",
    "\n",
    "X = train[a_cols + num_cols + cat_cols]\n",
    "y = train['Class/ASD']\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "        ('a', 'passthrough', a_cols),\n",
    "        ('num', 'passthrough', num_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "      ])\n",
    "\n",
    "model = Pipeline([('prep', pre),\n",
    "                  ('clf',  LogisticRegression(max_iter=1000, class_weight='balanced'))])\n",
    "\n",
    "# 80/20 stratified split\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb36f533",
   "metadata": {},
   "source": [
    " Fit & score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8707805a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC: 0.900\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_tr, y_tr)\n",
    "pred = model.predict_proba(X_val)[:,1]\n",
    "auc_score = roc_auc_score(y_val, pred)\n",
    "print(f'Validation AUC: {auc_score:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e82108",
   "metadata": {},
   "source": [
    "Remove leaking result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c06be6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC (no result): 0.917\n"
     ]
    }
   ],
   "source": [
    "# Create dataset without the 'result' column\n",
    "X_no_result = train[a_cols + ['age'] + cat_cols]\n",
    "\n",
    "# Create new pipeline without 'result' feature\n",
    "pre2 = ColumnTransformer([\n",
    "        ('a', 'passthrough', a_cols),\n",
    "        ('num', 'passthrough', ['age']),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "      ])\n",
    "\n",
    "model2 = Pipeline([('prep', pre2),\n",
    "                   ('clf',  LogisticRegression(max_iter=1000, class_weight='balanced'))])\n",
    "\n",
    "# Split data properly\n",
    "X_tr2, X_val2, y_tr2, y_val2 = train_test_split(X_no_result, y, \n",
    "                                                test_size=0.2, \n",
    "                                                random_state=42, \n",
    "                                                stratify=y)\n",
    "\n",
    "# Fit and evaluate model\n",
    "model2.fit(X_tr2, y_tr2)\n",
    "pred2 = model2.predict_proba(X_val2)[:,1]\n",
    "auc_score2 = roc_auc_score(y_val2, pred2)\n",
    "print(f'AUC (no result): {auc_score2:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "435f04de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New AUC (no result): 0.917\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_val, pred2)\n",
    "print('New AUC (no result):', round(auc, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a890db",
   "metadata": {},
   "source": [
    "Fairness snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cd1418d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUC by gender\n",
      "gender\n",
      "f    0.896\n",
      "m    0.920\n",
      "dtype: float64\n",
      "\n",
      "AUC by ethnicity\n",
      "ethnicity\n",
      "Asian              1.000\n",
      "Black                NaN\n",
      "Hispanic             NaN\n",
      "Latino               NaN\n",
      "Middle Eastern     0.947\n",
      "Others             0.667\n",
      "Pasifika           0.562\n",
      "South Asian        0.750\n",
      "Turkish              NaN\n",
      "White-European     0.806\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nsi_d\\AppData\\Local\\Temp\\ipykernel_15460\\750393480.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  print(val_df.groupby(grp).apply(lambda d: roc_auc_score(d['true'], d['prob'])).round(3))\n",
      "c:\\Users\\nsi_d\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nsi_d\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nsi_d\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nsi_d\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nsi_d\\AppData\\Local\\Temp\\ipykernel_15460\\750393480.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  print(val_df.groupby(grp).apply(lambda d: roc_auc_score(d['true'], d['prob'])).round(3))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "val_df = X_val.copy()\n",
    "val_df['true'] = y_val\n",
    "val_df['prob'] = pred2\n",
    "for grp in ['gender','ethnicity']:\n",
    "    print('\\nAUC by', grp)\n",
    "    print(val_df.groupby(grp).apply(lambda d: roc_auc_score(d['true'], d['prob'])).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99c0e17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New AUC (no result): 0.917\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_val, pred2)\n",
    "print('New AUC (no result):', round(auc, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b7ec622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ethnicity\n",
       "White-European     54\n",
       "Middle Eastern     20\n",
       "Asian              15\n",
       "Pasifika           10\n",
       "South Asian         9\n",
       "Black               8\n",
       "Others              7\n",
       "Latino              2\n",
       "Hispanic            1\n",
       "Turkish             1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df['ethnicity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a52899",
   "metadata": {},
   "source": [
    "collapse rare ethnicities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b34aa641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full-train counts:\n",
      "eth_group\n",
      "White-European     257\n",
      "Other              237\n",
      "Middle Eastern      97\n",
      "Asian               67\n",
      "Black               47\n",
      "South Asian         34\n",
      "Pasifika            32\n",
      "Others              29\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for df in (train, test):\n",
    "    mask = df['ethnicity'].isin(['Hispanic','Latino','Turkish','others']) | \\\n",
    "           (df['ethnicity'].isna()) | \\\n",
    "           (df['ethnicity'] == '?')\n",
    "    df['eth_group'] = df['ethnicity'].where(~mask, 'Other')\n",
    "\n",
    "# sanity counts on full train\n",
    "print('Full-train counts:')\n",
    "print(train['eth_group'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ac56e2",
   "metadata": {},
   "source": [
    " final grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7385fc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (train, test):\n",
    "    df['eth_group'] = df['ethnicity'].astype(str).replace({'?':'Other','others':'Other'})\n",
    "    # combine the two Others\n",
    "    df['eth_group'] = np.where(df['eth_group'].isin(['Others','Other']),'Other',df['eth_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9edab8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUC by eth_group\n",
      "eth_group\n",
      "Asian              1.000\n",
      "Black                NaN\n",
      "Hispanic             NaN\n",
      "Latino               NaN\n",
      "Middle Eastern     0.947\n",
      "Other              0.667\n",
      "Pasifika           0.562\n",
      "South Asian        0.750\n",
      "Turkish              NaN\n",
      "White-European     0.806\n",
      "nan                  NaN\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nsi_d\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nsi_d\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nsi_d\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nsi_d\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nsi_d\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nsi_d\\AppData\\Local\\Temp\\ipykernel_15460\\739468834.py:4: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  print(val_df.groupby('eth_group').apply(lambda d: roc_auc_score(d['true'], d['prob'])).round(3))\n"
     ]
    }
   ],
   "source": [
    "val_df['eth_group'] = val_df['ethnicity'].astype(str).replace({'?':'Other','others':'Other'})\n",
    "val_df['eth_group'] = np.where(val_df['eth_group'].isin(['Others','Other']),'Other',val_df['eth_group'])\n",
    "print('\\nAUC by eth_group')\n",
    "print(val_df.groupby('eth_group').apply(lambda d: roc_auc_score(d['true'], d['prob'])).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b4d0fe",
   "metadata": {},
   "source": [
    "full-train confusion-matrix counts by group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b856e531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nan</th>\n",
       "      <td>203</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>192</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White-European</th>\n",
       "      <td>257</td>\n",
       "      <td>116</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Middle Eastern</th>\n",
       "      <td>97</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pasifika</th>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black</th>\n",
       "      <td>47</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asian</th>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turkish</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Asian</th>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Latino</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   N   TP  FP  FN   TN  Recall   FPR\n",
       "nan              203    4   4   3  192    0.57  0.02\n",
       "White-European   257  116  70   5   66    0.96  0.51\n",
       "Middle Eastern    97    5   4   1   87    0.83  0.04\n",
       "Pasifika          32    6   8   0   18    1.00  0.31\n",
       "Black             47    5   6   1   35    0.83  0.15\n",
       "Other             32    1   3   1   27    0.50  0.10\n",
       "Hispanic           9    2   2   0    5    1.00  0.29\n",
       "Asian             67    3   2   1   61    0.75  0.03\n",
       "Turkish            5    0   1   0    4    0.00  0.20\n",
       "South Asian       34    2   1   1   30    0.67  0.03\n",
       "Latino            17    3   2   1   11    0.75  0.15"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# fit on full train, predict on full train (quick sanity)\n",
    "model2.fit(X_no_result, y)\n",
    "y_pred_full = model2.predict(X_no_result)\n",
    "\n",
    "def cm_stats(group_col, group_val):\n",
    "    mask = train[group_col] == group_val\n",
    "    cm = confusion_matrix(y[mask], y_pred_full[mask])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    return {'N': mask.sum(), 'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn,\n",
    "            'Recall': tp/(tp+fn+1e-9), 'FPR': fp/(fp+tn+1e-9)}\n",
    "\n",
    "# eth_group counts\n",
    "stats = pd.DataFrame([cm_stats('eth_group', g) for g in train['eth_group'].unique()])\n",
    "stats.index = train['eth_group'].unique()\n",
    "stats.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e832b71",
   "metadata": {},
   "source": [
    "Interpretation of the full-train table\n",
    "\n",
    "- **White-European** dominates (257 rows) but has **very high FPR (0.51)** → many false alarms.  \n",
    "- **Small groups** (Turkish, Other, South-Asian) have **≤ 5 ASD cases** → metrics unstable.  \n",
    "- **Pasifika & Hispanic** show **perfect recall** but tiny N, so not reliable.\n",
    "\n",
    "Decision  \n",
    "Because sample sizes are **too small for stable per-ethnicity thresholds**, we will:\n",
    "\n",
    "1. **Keep a single global model** (no per-group tuning).  \n",
    "2. **Flag small-group uncertainty** in the interface.  \n",
    "3. **Proceed to final model training + calibration** on the entire train set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc84102",
   "metadata": {},
   "source": [
    "# Step 3 – Final Model & Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b53070",
   "metadata": {},
   "source": [
    "full-pipeline with calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b24961e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brier score (lower = better): 0.081\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "# Re-fit on full training data\n",
    "model2.fit(X_no_result, y)\n",
    "\n",
    "# Calibrate via Platt scaling\n",
    "cal = CalibratedClassifierCV(model2, method='sigmoid', cv=5)\n",
    "cal.fit(X_no_result, y)\n",
    "\n",
    "# Predict probabilities on training data for sanity\n",
    "proba_train = cal.predict_proba(X_no_result)[:,1]\n",
    "brier = brier_score_loss(y, proba_train)\n",
    "print(f'Brier score (lower = better): {brier:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf9358b",
   "metadata": {},
   "source": [
    "# Save Calibrated Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8606a0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/calibrated_lr.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "models_dir = os.path.join(os.path.dirname(os.path.abspath('__file__')), '..', 'models')\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Save the calibrated model\n",
    "model_path = os.path.join(models_dir, 'calibrated_lr.pkl')\n",
    "joblib.dump(cal, model_path)\n",
    "print(f'Model saved to {model_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
